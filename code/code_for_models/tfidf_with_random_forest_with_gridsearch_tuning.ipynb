{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TFIDF with Random Forests with GridSearch tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stops = stopwords.words('english')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/df_onion_not_onion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify= y, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tvec_r_forest = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('r_forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe_tvec_r_forest_params = {\n",
    "    'tvec__max_features': [25_000, 60_000],\n",
    "    'tvec__stop_words': [None, nltk_stops],\n",
    "    'tvec__ngram_range': [(1, 1), (1, 4)],\n",
    "    'r_forest__n_estimators': [5, 10, 20, 100],\n",
    "    'r_forest__max_depth': [3, 4, 5, 7, 100],\n",
    "    'r_forest__min_samples_leaf': [1, 2], \n",
    "    'r_forest__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "gs_tvec_r_forest = GridSearchCV(estimator= pipe_tvec_r_forest,\n",
    "                                param_grid= pipe_tvec_r_forest_params,\n",
    "                                cv= 3,\n",
    "                                verbose= 1,\n",
    "                                n_jobs= -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 640 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tvec',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words...\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 4)],\n",
       "                         'tvec__stop_words': [None,\n",
       "                                              ['i', 'me', 'my', 'myself', 'we',\n",
       "                                               'our', 'ours', 'ourselves',\n",
       "                                               'you', \"you're\", \"you've\",\n",
       "                                               \"you'll\", \"you'd\", 'your',\n",
       "                                               'yours', 'yourself',\n",
       "                                               'yourselves', 'he', 'him', 'his',\n",
       "                                               'himself', 'she', \"she's\", 'her',\n",
       "                                               'hers', 'herself', 'it', \"it's\",\n",
       "                                               'its', 'itself', ...]]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tvec_r_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9673333333333334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tvec_r_forest.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8064"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tvec_r_forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 640 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 225 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 475 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 825 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1275 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1825 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 640 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 474 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1274 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1824 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 640 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 823 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1273 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1823 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7938666666666666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(gs_tvec_r_forest, X_train, y_train, cv= 3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r_forest__max_depth': 100,\n",
       " 'r_forest__min_samples_leaf': 1,\n",
       " 'r_forest__min_samples_split': 5,\n",
       " 'r_forest__n_estimators': 100,\n",
       " 'tvec__max_features': 25000,\n",
       " 'tvec__ngram_range': (1, 4),\n",
       " 'tvec__stop_words': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tvec_r_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
